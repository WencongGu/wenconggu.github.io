---
title: 基于链式安全多方计算的隐私保护联邦学习框架
date: 2023-09-06 22:59:22
tags: Pivacy Preserving, Algorithm
mathjax: true
---



**摘要：** 联邦学习（FL）是物联网智能^[IoT intellegence]领域一项前景广阔的新技术。然而，在 FL 中交换与模型相关的数据可能会泄露参与方的敏感信息。为了解决这个问题，我们基于一种创新的链式安全多方计算技术，提出了一种新型隐私保护联邦学习框架，并将它命名为 chain-PPFL。我们的方案主要利用了两种机制：一种是在多方计算中使用链式安全计算技术；另一种是在多方计算中使用链式安全计算技术。我们的方案主要利用了两种机制：1）保护参与者之间交换信息的单一掩码机制^[single-masking mechanism]；2）链式通信机制，该机制使得掩码^[mask，根据语境下文作名词译为掩码，作动词译作遮罩] 信息可以利用串行链式结构^[serial chian frame，其中serial在下文反复出现，文中统一译作“串行的”]在各参与方之间传输。我们使用两个公共数据集（MNIST 和 CIFAR-100）进行了大量模拟实验，并在训练准确性、泄漏防御能力上与其他先进技术进行了比较。实验设置了两种数据样本分布（IID 和 NonIID）和三种训练模型（CNN、MLP 和 L-BFGS）。实验结果表明，在牺牲了一定的通信成本时，chain-PPFL 方案可以实现可观的隐私保护（$\epsilon$趋向于0的差分隐私），并且不会影响训练模型的准确性和收敛速度。

**索引主题：** 联邦平均算法（FedAVG），联邦学习（FL），隐私保护，安全多方计算（SMC）

<!-- more -->

 <font size=4, color=blue>***something wrong with mathematical formulas***</font>

## I. 介绍

联邦学习（FL）的概念最初是 Google 在2016年提出的。FL 的主要原理是通过基于分布在多个设备上的数据集来训练机器学习模型，从而保护数据所有者（即参与方）的隐私。在整个训练过程，各参与方仅仅与服务器交换梯度，而不是原始数据或者加密/脱敏数据。在FL中，有必要建立一个协调服务器，负责汇总^[aggregate，根据语境下文或译作汇总或译作聚合] 参与方上传的梯度，并将更新后的结果反馈给参与方。

FL 由于其隐私保护的能力得到了学术界和工业界的广泛关注。然而，近期的一些研究显示交换梯度对于参与方来说仍不够安全。从共享的数据中（即梯度）仍然有可能获取到用于训练的隐私数据 [4]–[6]。

为了加强 FL 训练过程中的隐私保护，人们提出了许多方案和策略，主要基于差分隐私（DP）技术[7]-[10]和安全多方计算（SMC）技术[11]-[17]。然而，这些方案很难应用到实际的系统中。首先，DP 技术依赖于在原始梯度中添加噪声来保护隐私，这就使得权衡模型准确性和隐私保护水平变得很困难 [5]、[7]、[8]。其次，基于 SMC 的方案面临着巨大通信和计算开销，因为 SMC 中的同态加密（HE）机制和秘密共享机制都会大量消耗计算和通信资源。例如，有些方案要么计算成本高，要么通信成本高，要么限制参与方的数量，要么需要额外的信任假设 [14]、[18]、[19]。在许多实际应用场景中，尤其是移动计算场景中，上述方法的工作量和复杂性远远超出了设备的处理能力，这使它们的部署面临挑战。

为了克服 FL 的这些弱点，我们提出了一种基于新型链式 SMC 技术的新型隐私保护 FL 框架，并将其命名为 chain-PPFL。我们的方案可以从两个方面来说明。第一，将参与者组织成链式结构。例如，同一区域内的参与者由于其信息交换速度快，可以形成一个链。对于每个已形成的链，每个参与者都会将掩码信息添加到其梯度中以获得输出。父级参与者的输出被其子级参与者用作掩码信息以保护其梯度。第二，参与者以灵活的分布式方式形成链。在每一轮迭代中，每条链都有一个独一无二的令牌，这个令牌可以由每一个参与者所独占。拥有令牌的当前参与者将在不获取掩码信息的情况下，从其余邻居中随机选择下一个节点作为后代节点。然后，当前节点将其输出传递给后代节点。最后一个参与者将其输出作为最终结果发送回服务器，这个最终结果包含了同一链中所有参与者梯度信息的聚合。服务器为每条链生成一个随机数，将其传输给每条链的第一个参与者，这些随机数被用以启动信息交换。由于单个参与者的输出都会用先前参与者的输出做掩码处理，所以敌手（即好奇节点）无法从参与者的输出中获得任何隐私敏感的细节（即梯度）。因此，chain-PPFL 等同于 $\epsilon \to 0$ 的 DP。

我们的主要贡献如下

1) 在 “ 诚实但好奇 ” 的环境设置下，所提出的方案能在不降低模型精度的情况下实现隐私保护，并且接近于比较基准的 FL 算法（即 FedAVG 算法 [1]），同时优于基于 DP 的 FL 算法 [9]。
2) 我们的 chain-PPFL 方案的通信和计算复杂度远低于传统的基于 SMC 的方案。
3) 所提出的 chain-PPFL 架构相对简洁，在如物联网等实际 FL 应用场景中的设备上易于部署。
4) 我们提供了 chain-PPFL 的实例。Github 链接为[https://github.com/ITSEGMQ/Chain-PPF](https://github.com/ITSEGMQ/Chain-PPFL)

本文的其余部分安排如下。在第二节中，我们首先讨论了相关工作。在第三部分，我们详细描述了 chain-PPFL 的架构和实现。在第四节中，我们提供了与其他方案的对比分析。在第五节中，我们给出了对比实验，并讨论了实验结果。最后，第六节总结了本文的结果。

## II. 相关工作

联邦学习正越来越多地被应用于隐私敏感的多方协作环境中，例如 Google 输入工具、智能认知系统、人类情感识别等 [20]–[24]。为了协调各个分布式计算节点，需要传输模型相关的信息 [1]，这就需要对交换的数据（如梯度）进行隐私保护，以防止原始数据中的敏感信息通过公开信息的反向推理而泄露 [4]-[6], [25]。目前，FL 中的隐私保护主要基于两种技术实现：1）DP，2）SMC。

### *A. 差分隐私*

使用敌手分析 FL、DP 中的数据/模型是隐私保护中的一种很常见的方法，主要用于量化效果和限制泄漏敏感数据。它使用了一种随机机制（例如引入某种随机子采样^[sandom subsampling]或者加入随机噪声）来扰乱用户进程的输入输出，使得用户进程的结果在一定程度上可以抵抗隐私分析。用差分私有机制^[differentially private mechanism]逼近一个确定性实值函数^[deterministic real-valued] $f:D\to \mathbb{R}$ 的一种常见方式是使用附加噪声，这个噪声是从 $f$ 的敏感度 $\mathcal{S}_f$ 估计得到的，而敏感度的定义是距离 $|f(d)-f(d')|$ 的最大值，其中 $d$ 和 $d'$ 是相邻的输入。例如，Laplace 机制定义为 $f(d')\triangleq f(d)+\mathcal{L}(0,\frac{\mathcal{S}_f^2}{\epsilon})$。$\mathcal{L}(0,\frac{\mathcal{S}_f^2}{\epsilon})$ 是Laplace分布的噪声，用来实现 $\epsilon$-DP。除了 Laplace 机制，也经常使用Gauss 机制。在基于 DP 的 FL 中，随着 $\epsilon$ 值的减小，加入的噪声会变大，隐私保护的级别也会提高。同时，由于噪声变大，训练的模型精度也随之下降。反之亦然。

然而，由 Zhu 等人 [5] 提出、由 Zhao 等人 [6] 完善的深层梯度泄漏^[deep-leakage-from-gradients]（DLGs）方法在实验中显示，当加入 DP 算法的噪声方差不超过 $10^{-4}$ 时，共享的噪声化梯度使用 DLG 方法后会泄漏隐私信息。DLG 方法只有在噪声方差大于 $10^{-3}$ 时才会失效，但此时的噪声会显著降低模型的精度。相对地，我们提出的方法可以在保护隐私的同时不降低模型精度。

### *B. 安全多方计算*

利用SMC来实现本地模型更新的安全聚合是一项很有前景的技术。目前有多种不同的方式，例如HE、秘密共享^[secret sharing]、成对掩码^[pairwise making]等，下面简单介绍了这些技术。

1) *同态加密（HE）：* HE 方案在不解密的情况下直接对密文进行复杂的数学运算 [26]-[31]。由于 HE 在计算过程中不直接使用明文，因此被认为是实现 SMC 协议的理想方法 [13]。

   在联邦设置^[federated setting，下文根据语境翻译为联邦设置或者联邦环境]中，Hardy 和 Aono 等人描述了几种基于加法 HE（AHE）方案的隐私保护解决方案 [11]、[12]、[18]。因为在 HE 中没有混淆/扰乱操作，所以训练模型的精度几乎不受影响。然而，基于 HE 的方法面临着几个挑战。第一，HE算法，即便是比较简单的 AHE 算法也需要相应的大量计算资源或者特定的硬件设备。第二，在实际问题中要实现实时吞吐，大规模的并行化是不可避免的（有些任务可能无法并行化）[32]。第三，一些基于 HE 的解决方案可能需要一个可信的第三方来完成加密/解密操作，而在标准的 FL 中一般不使用可信的非串通^[noncolluding，下文的 “串通” 译自 "collude" "collusion"]方。相对地，我们的设计计算量小且不依赖可信第三方。

2) *秘密共享：* 秘密共享是一种加密方法，它将一个秘密拆分成多个共享，并将共享分配给多方，只有当多方将各自的共享汇集在一起时，才能重构该秘密 [33]。为了安全地聚合用户更新的梯度，有人提出了几种基于秘密共享机制的保护隐私和安全聚合方法 [14]-[17] 。

   上述方案与我们的相似。在我们的方案中，在传输掩码信息之前不需要额外的操作，因为我们的方案使用了点对点加密安全传输通道^[peer-to-peer encrypted secure transmission channel]。因此，我们的方法更加高效并且只需较少的资源。
   
3) *成对掩码：* 成对掩码在 [34]–[36] 中已有探讨。在 [34] 和 [36] 提出的协议中，成对的用户使用 Diffie-Hellman 密钥交换来商定成对掩码。然而，当参与用户数量 $N\gg 1$ 时，聚合结果通常不足以为单个用户提供合理的隐私保护，因此，AHE 技术被用以保护上传的每个局部掩码值 [14]。他们的方案与基于 DP 的方案不相上下，但其协议中的数据复原阶段有所不足 [36]，而且会由于 AHE 而产生额外的开销。与它们相比，我们的 chain-PPFL 方案在通信和计算成本上更为高效。

## III. 结构与方法

在本节中，我们将详细介绍 chain-PPFL，它可以在 FL 中实现模型参数的聚合，同时在不影响模型精度的情况下保护参与者的私人信息。表 I 列出了文中使用到的符号及其含义。

表 I，符号含义

| 符号                                                | 含义                                          |
| :-------------------------------------------------- | :-------------------------------------------- |
| $n$                                               | 数据样本的总数                                |
| $\mathcal{P}_d$                                   | n 个数据样本的一个划分^[partition]                        |
| $D$                                               | 由$\mathcal{P}_d$ 得到的数据划分的数量      |
| $n_d$                                             | 每个数据划分中数据样本的数量                  |
| $K,k$                                             | 用户数量及其索引                              |
| $C,m$                                             | $K$ 个用户的划分^[fraction]比率，每个划分有$m$个用户 |
| $S_t$                                             | $m$ 个用户的一个随机集合                    |
| $B$                                               | 本地小批次的大小                              |
| $E$                                               | 本地循环次数                                  |
| $\eta$                                            | 学习率                                        |
| $t$                                               | 训练轮次                                      |
| $w^t_{G_{\ast}}$                                   | 第$t$ 轮的全局模型参数                      |
| $w^{t}_{i}$                                       | 第$t$ 轮的用户 $i$ 的模型参数             |
| $\Delta \ell(w;b)$                                | 每个批次中用户本地计算的梯度                  |
| $\mathbf{PRN}^{t}$                                | 聚合节点生成的随机数                          |
| $U_0^t$                                           | 聚合节点发送的信息                            |
| $token^t_0$                                       | 聚合节点构建的令牌                            |
| $n_p$                                             | 计算参与者数量的计数器                        |
| $Time_{limit}$                                     | 控制轮次持续时间的倒计时器                    |
| $U_0^i$                                           | 用户$i$ 发送的信息                          |
| $token^t_0$                                       | 用户$i$ 构建的令牌                          |
| $\mathcal{L}(0,\frac{\mathcal{S}_f^2}{\epsilon})$ | Laplace 分布的噪声                            |
| $\mathcal{S}_f^2$                                 | DP 隐私敏感度                                 |
| $\epsilon$                                        | DP 隐私预算                                   |

### *A. 问题前言*

FL 通常旨在极小化分布在多个设备上的异构数据的经验风险^[emperical risk] [37]。在每次迭代训练开始前，每个参与用户都会从聚合节点（或服务器）获取全局模型参数。然后，用户利用全局模型参数使用本地数据集训练本地模型，并将新的本地模型参数作为本地更新发送到聚合节点。聚合节点通过聚合选定的几个用户的本地更新来计算新的全局模型参数。不断循环这个过程直到满足终止条件。

在一个联邦设置环境中，优化对象是

$$
\min_{w\in \mathbb{R}^d}f(w),\hspace{0.5em}\text{where}\hspace{0.5em} f(w)\triangleq\frac{1}{n}\sum_{i=1}^{n}f_i(w)
\tag{1}
$$

如果有 $D$ 个数据分区 $n_d = |\mathcal{P}_d|$，其中 $P_d$ 是 $n$ 个数据样本的划分。如果划分 $P_d$ 是均匀随机设置的，那么

$$
\begin{aligned}
 \text{let} \quad F_d(w)=\frac{1}{n_d}\sum_{i\in \mathcal{P}_d}f_i(w)&\\
 \text{then} \quad f(w)=\sum_{d=1}^{D}{n_d\over n}F_d(w)&
\end{aligned}
\tag{2}
$$

FedAVG [1] 作为一种经典的 FL 算法被广泛使用，本文也将其作为基准算法。这里，我们假设有一个聚合节点和 $K$ 个用户，每个用户自己拥有固定的本地数据集。

在 FedAVG 算法 [1] 中，$K$ 个用户以 $k$ 为索引；$B$ 是 是局部小批次大小；$E$ 是本地循环次数；$\eta$ 是学习率。FedAVG 算法的具体细节见算法 1。

![算法1 FedAVG](image/chain-PPFL/算法1联邦平均.png)

在算法 1 中，聚合节点的工作包括分发全局模型参数，聚合来自 $m$ 个用户的本地更新。每个用户根据全局模型参数 $w^t_G$ 在本地数据集上完成训练任务，并在本轮上传本地模型更新。用户在本地使用小批次的 SGD（$B$ 个批次）算法。参与用户 $i$ 在第 $t$ 轮的目标是找到本地的最优参数 $w^{t^{*}}_i$，使函数 $f(w^{t}_i)$ 最小化，即

$$
w^{t^{\ast}}_i = \argmin_{w_i^t} f(w_i^t) \tag{3}
$$

实际上，在FedAVG中，服务器会选取 $K$ 个参与者再计算平均聚合值作为全局权重 [25]

$$
w^{t+1}_{G}=\frac{1}{K}\sum_{i=1}^{K}w_i^{t^{*}}
$$


### *B. 提出的结构*

我们提出的 chain-PPFL 采用了一种新颖的链式通信机制，通过串行链式结构在参与者之间传输掩码信息。在有中心服务器的基准联邦环境中，如图1展示的，服务器的主要工作包括: 1) 训练之前广播参与用户列表；2) 负责生成随机数用以遮罩（mask）；3) 生成令牌；4) 对从最后一个用户收到的令牌中提取的聚合结果求平均；5) 将全局模型参数反馈给用户。

![图1 chain-PPFL的结构](./image/chain-PPFL/chain-PPFL结构.png)

参与的客户端可以根据从服务器接收到的用户列表创建自己的相邻用户列表。在不同的网络环境中，我们可以利用不同的方法建立相应的邻居列表。例如，我们可以在 LAN （局域网）环境中使用泛洪法^[the flood method]建立邻居列表，也可以在蜂窝网络中使用 Vela 等人提出的方法建立邻居列表 [38]。在 P2P 网络中，我们可以使用 Zhao 等人提出的方法来建立邻居列表 [39]。由于这不是本文讨论的核心问题，我们假设每个参与的用户在训练开始前已经建立好了邻居列表。为了在每一轮中构建链式通信结构，每个参与者（包括服务器）都会从其邻居列表中随机选择一个邻居作为下一个节点。链式通讯结构的构建在 III-C 节有详细介绍。

每一轮，服务器都会为每个链生成一个独一无二的令牌，该令牌可由每个用户独家拥有，并通过用户间的链式通信机制串行传输。我们的方案使用单一遮罩机制来保护隐私。当前拥有令牌的参与者将在不获取掩码（mask）信息的情况下，从其余邻居中随机选择下一个节点作为后代节点。然后，当前参与者将更新后的令牌发送给后代节点。最后一个参与者将其更新后的令牌（包含同一链条上所有参与者模型参数的聚合）发回服务器。由于单个参与者在链式聚合过程中使用其前者的输出来遮罩处理自己的输出，因此敌手（即好奇节点）在没有事先串通^[collusion]的情况下无法从参与者的输出中获取任何敏感隐私信息。

图2显示了 chain-PPFL 同样能够被应用在由 Liu 等人讨论的边缘计算^[edge-computing]场景 [40]。多个边缘服务器执行部分模型聚合，中心服务器（或云服务器）聚合来自边缘服务器的全局模型更新。通常，在边缘云中，参与方之间的网络延迟非常小，因此它们可以在链条中快速交换信息。因此，chain-PPFL 可以在通讯和隐私保护方面取得更好的平衡。

![图2 边缘计算的chain-PPFL](image/chain-PPFL/边缘计算的chain-PPFL.png)

### *C. Chain-PPFL 算法*

在第二节中，我们讨论了信息交换中隐私保护所面临的挑战。在本文中，我们只考虑所有参与者之间的隐私保护问题，并假设所有节点都是可信任但好奇的^[trust-but-curious]，并且传输通道都是可靠且安全的。第 $i$ 轮的 chain-PPFL 链式程序如下。

*步骤 1:*

*聚合节点：* 聚合节点将全局参数 $w_G^t$ 广播至全部用户，生成伪随机数 $\mathrm{PRN}^t$（$\mathrm{PRN}^t\in \mathbb{R}^d$，$d$ 是 $w$ 的维度）作为遮罩，令U_0^t=$\mathrm{PRN}^t$。然后，聚合节点生成 $token^t_0$$(t, U_t^0, n_p, Time_{limit})$，其中 $n_p$ 是计数器，用来记录参与者的数量；$Time_{limit}$ 是倒计时器，用于控制每个回合的持续时间。根据本文的假设，节点无需检查令牌。服务器将令牌发送到第一个参与者（命名为用户 1），这个参与者是从当前轮次中的邻居用户中随机选取的。

*步骤 2:*

*参与者 1：* 用户 1 是第 $t$ 轮的第一个参与者，本地最优参数 $w^{t^{*}}_1$ 是它的本地更新。本地模型的训练过程与 FedAVG 一样。接下来，用户 1 计算

$$
U^t_1=w^{t^{*}}_1+U_0^t \tag{5}
$$

并通过更新 $token^t_0$ 来将掩码结果 $U^t_1$ 传输给下一位参与者，这个参与者是从用户 1 的邻居用户中随机选取的。

*参与者 $i$：* 用户 $i$ 计算本地更新 $w^{t^{*}}_i$，使用用户 $i-1$ 的输出作为遮罩计算

$$
U^t_i=w^{t^{*}}_i+U_{i-1}^t=\sum_{j=1}^{i}w^{t^{*}}_j+U_0^t \tag{6}
$$

并通过更新 $token^t_i$ 来将结果 $U^t_{i}$ 传输给下一位参与者（命名为用户$i+1$），这个参与者是从用户 $i$ 的邻居用户中随机选取的。

*参与者 $K$：* 用户 $K$ 计算本地更新 $w^{t^{*}}_K$，使用用户 $K-1$ 的输出作为遮罩计算

$$
U^t_i=w^{t^{*}}_K+U_{K-1}^t=\sum_{j=1}^{K}w^{t^{*}}_j+U_0^t \tag{7}
$$

假设此时 $Time_{limit}\le0$，那么用户 $K$ 就是最后的节点，所以用户 $K$ 应当通过更新 $tonken^t_K$ 将结果 $U^t_K$ 传送到聚合节点。

*聚合节点：* 聚合节点从第 $K$ 个参与者接收到 $token^t_K$，并计算下一轮的全局权重

$$
w^{t+1}_G={1\over K}(U^{t}_K-U_{0}^t)={1\over K}\sum_{i=1}^{K}w^{t^{*}}_i \tag{8}
$$

转到步骤 1。

chain-PPFL 算法的细节见算法 2。

![算法2 Chain-PPFL](image/chain-PPFL/算法2chain-PPFL.png)

## IV. 分析与比较

在本节中，我们将从以下三个方面对 chain-PPFL 进行分析： 1) 训练精度；2) 隐私保护水平；3) 延迟。在分析的基础上，我们将 FedAVG 同 chain-PPFL、DP-based FL 和AHE-based FL 进行比较，详细分析见表 II。

表 II，同其他方法的比较

|                  | 训练精度<br />VS FedAVG | 隐私保护水平 | 延迟<br />VS FedAVG |
| :--------------: | :----------------------: | :----------: | :-----------------: |
|   DP-based FL   |           降低           |      弱      |        相同        |
| AHE-based FL[14] |           相同           |      强      |        极高        |
|    Chain-PPFL    |           相同           |    组内强^[strong in group]    |       相对高       |

### *A. 精度分析*

在 FedAVG 的每一轮中，服务器都会随机选择一个用户片段，并将本地更新聚合的平均值作为为全局模型参数 $w^t_G$，如式（5）所示。而在 chain-PPFL 中，聚合节点从最终用户处获取模型参数的聚合并求平均值，如式 (9) 所示。由于 chain-PPFL 从邻居中选择下一个参与者的随机性，如果使用适当的 $Time_{limit}$，使用我们的方法训练模型的精度与 FedAVG 给出的值相同。由于 $Time_{limit}$ 与计算和通信延迟有关，我们将在第 IV-C 节讨论 $Time_{limit}$ 的设置。大部分基于 SMC 的方法不修改 FL 的核心算法，且仅提供了安全计算环境，所以训练模型的精度基本取决于 FedAVG 给出的值。然而，在基于 DP 和成对掩码技术的算法中，训练精度出现了不同程度的下降，精度下降的程度取决于 $\epsilon$-DP 的值。实际上，加入的噪声值越大，精度损失越大，这在 [5] 和 [6] 中有实验证明。

### *B. 隐私保护水平分析*

FL 中的对原始数据的隐私保护是可以接受的，但是在参与者之间共享的梯度仍然有可能泄漏敏感信息，甚至是原始的训练样本。最新的研究工作注重于对与训练模型相关的数据的隐私保护上，这些数据被用于在协作参与者之间交换。接下来，我们会分析一些主流方法的安全性和隐私保护水平。

在基准的 FL 中，本地更新的数据是训练模型的权重值  $w_i^{t^{*}}$ ，如公式（4）所示。

在应用了 DP（使用Laplace机制）的 FL 中，上传的噪声数据是 $w_i^{t^{*}}+\mathcal{L}(0,\frac{\mathcal{S}_f^2}{\epsilon})$ [9]，其中 $\mathcal{L}(0,\frac{\mathcal{S}_f^2}{\epsilon})$ 是 Laplace 分布的噪声，$\mathcal{S}_f^2$ 是隐私敏感度，$\epsilon$ 是隐私保护预算。

[5] 指出，公共共享的数据在 FL 和 应用了 DP 的 FL 中都被实验证明有极高风险泄漏隐私。在 chain-PPFL 中，在相邻节点交换的数据是 $ U_i^t $，即 $U^t_i=\sum_{j=1}^{i}w_j^{t^{*}}+\mathrm{PRN}^t$，其中 $\mathrm{PRN}^t$ 是由聚合节点给出的随机常数。

我们的方法等价于 $\epsilon\to 0$ 时的基于 DP 的无串通 FL，使敌手（即好奇节点）几乎无法从接收到的信息中获取任何隐私敏感细节。如果聚合节点只获得本地更新的总和，则要求每轮至少有两个节点参与协作训练。这可以通过选取合适的 $ Time_{limit} $ 实现。使用基于 AHE 的方法时，参与者会上传本地权重值 $w_i^{t^{*}}$ 的密文，在基于 HE 的更加复杂的方法中，上传的会是本地遮罩后权重的密文。隐私保护的水平相当于加密算法的安全性。

### *C. 延迟分析*

在联邦环境中，第 $i$ 轮的延迟包含3个方面：1) $T_{local}^i$，各个参与者计算本地模型参数的延迟；2) $T_{global}^i$，中心节点计算全局模型参数的延迟；3) $T_{comm,up}^i$，上传本地更新的通信延迟。在此，我们不考虑向本地节点广播全局模型所需的时间，因为本文所用于比较的所有方法所需时间都相同。为了便于推导，我们假设所有参与用户的基准 $T_{local}^i$ 和 $T^i_{comm,up}$ 都是相同的。参与基线 FL 的用户并行地将本地更新上传到服务器，因此基准 FL 中每轮延迟为 $T_{total}^i=T_{local}^i+T_{global}^i+T_{comm,up}^i$。

在应用了 DP 的 FL 中，计算本地模型参数 $T_{local,DP}^i$ 的延迟略高于基准 FL，主要是因为加入了噪声以实现隐私保护。所以总延迟为 $T_{total,DP}^i=T_{local,DP}^i+T_{global}^i+T_{comm,up}^i$。

至于基于 HE 的方法，本地节点的延迟 $T^i_{local,HE}$ 主要包含两部分：1) $T_{local}^i$，各个参与者计算本地模型参数的延迟；2) $T_{encrypt}^i$，将 HE 应用于本地模型参数的延迟，即，$T^i_{local,HE}=T_{local}^i+T_{encrypt}^i$。我们假设中心节点实现对聚合求和结果的解密，所以 $T^i_{global,HE}=T_{global}^i+T_{decrypt}^i$。因此，总延迟为 $T^i_{total,HE}=T_{local,HE}^i+T_{global,HE}^i+T_{comm,up}^i$，不考虑密钥生成和分发的时间。

在图 1 所示的 chain-PPFL 中通信延迟 $T_{comm,o}^i$ 包含两个部分：1) $T_{comm,sa}^i$，本地节点的通信延迟；2) $T_{comm,up}^i$，同其他方法相同，上传本地模型参数的延迟。此处为了便于推导，我们假设在参与者和它的邻居之间的通信延迟是相同的^[原文：the communication latency between a local participant and its neighbor is the same]，命名为 $T_{comm,nb}^i$，所以

$$
\begin{aligned}
T_{comm,o}^i&=T_{comm,sa}^i+T_{comm,up}^i\\
&=(K-1)\times T_{comm,nb}^i+T_{comm,up}^i
\end{aligned}
\tag{9}
$$

其中 $K$ 是每轮参与模型训练的用户数量。另外，聚合节点不需要计算综合，这是由参与者串行聚合的，但是要计算串行聚合结果的平均值。所以计算本地模型参数的延迟 $T_{local,o}^i$ 略低于基准 FL，且计算全局模型参数的延迟 $T_{global,o}^i$ 也比 $T_{ global}^i$ 更小。因此，我们方法的总延迟为 $T_{total,o}^i=T_{local}^i+T_{global,o}^i+T_{comm,o}^i$。计算时间方面，由于假设训练模型基准时间相同，有

$$
T_{local}^i<T_{local,o}^i<T_{local,DP}^i<T_{local,HE}^i
\tag{10}
$$

和

$$
T_{global,o}^i<T_{global}^i<T_{global,HE}^i
\tag{11}
$$

在通信延迟方面，当 $T_{comm,sa}^i\ll T_{comm,up}^i$ 时，即本地节点与聚合节点间的延迟更大时，有 $T_{total,o}^i\approx T_{total}^i$。否则，当 $T_{comm,sa}^i\ll T_{local}^i$ 或者 $T_{comm,o}^i\ll T_{local}^i$ 时，有 $T_{total,o}^i\approx T_{total}^i$。所以我们可以看到，影响我们算法效率的关键因素是任何本地参与者与其邻居之间的通信延迟 $T_{comm,nb}^i$。而且，由于我们算法的安全性，在 $\mathrm{Token}^t_i$ 中的 $Time_{limit}$ 应当比 $[T_{local}^i+T_{comm,nb}^i+T_{comm,up}^i]$ 更长。当 $Time_{limit}$ 大于 $[T_{local}^i+(n-1)T_{comm,nb}^i+T_{comm,up}^i]$ 时有 $n$ 个用户参与训练。

提出的 chain-PPFL 更适用于网络带宽大、延迟小的场景，如局域网或高速 P2P 网络。此外，chain-PPFL 框架还适用于没有中心节点的完全去中心化场景，在这种场景中，局部训练结果的聚合过程可以在节点之间的链条中串行完成。这是我们未来的工作方向之一。

## V. 实验

### *A. 实验设置*

我们模拟并比较了三种方案的训练精度，包括所提出的 chain-PPFL 算法、FedAVG 算法和 [9] 中的基于 Laplace 机制的 DP 算法。

根据 [1] 和 [7]，我们实验场景的联邦环境设置如下。

1) 用户数量 $K=100$。
2) 用户划分比率 $C=0.1$。
3) 本地小批次大小 $B=10$。
4) 本地循环次数 $E=5$。
5) 学习率 $\eta=0.1$。
6) 基于 DP 的 FL 分别固定 $\epsilon=8$和$\epsilon=1$。

在训练准确率的对比测试中，我们使用了MNIST 数字识别公共数据集。对于整体联邦环境设置^[comprehensive federated setting]，我们采用两种方法将 MNIST 数据划分^[partitoning]给用户[1]：1) IID，数据被洗牌并分成 100 个用户^[partitioned into 100 users]，每个用户接收 600 个示例；2) NonIID，数据按数字标签排序，分成 200 个大小为 300 的子集^[shard]。我们为每 100 个用户分配两个子集。此外，我们使用两个训练模型（类似于 [1] 和 [41]）：1) MLP，一个简单的多层感知系统，包含两个隐藏层，每个层有 200 个单元，使用 ReLU 激活函数；2) CNN，包含两个 5 $$ 5 卷积层、一个包含 512 个单元并使用 ReLU 激活函数的全连接层、以及一个 softmax 输出层的 CNN。我们使用文献 [5] 给出的 DLG 方法对泄漏防御^[leakage defence]分析进行了实验验证。在泄漏防御的对比测试中，我们使用了CIFAR-100 图像分类公共数据集和学习率为 1 的 L-BFGS 模型（与 [5] 中的相同）。我们使用 PyTorch [42] 作为实验平台。用以模拟实验的计算机配置：处理器为英特尔酷睿 i5-4570 CPU @ 3.20 GHz，内存为 8.0 GB，无 GPU。

### *B. 实验结果*

训练模型测试精度的比较结果如图 3 所示。基于 DP 的 FL 方案通过在原始梯度中添加噪声来保护隐私。为了提高隐私保护水平，有必要添加方差更大的噪声，也就是增加 $\epsilon$ 的值。但是，方差较大的噪声对训练精度有着更加显著的负面影响。从图 3 中的实验结果可以看出，用 chain-PPFL 训练的模型的精度接近于 FedAVG，并且比基于 DP 的 FL 高出 $0.1\%-2\%$，对于使用 MNIST 集且有 NonIID 划分的模型更是如此。对于 MNIST 集上带有 IID 划分的 MLP 模型，图 3(d) 显示 chain-PPFL 的准确率接近 FedAVG，略高于基于 DP 的 FL $0.2\%$ ($\epsilon = 8$) 到 $0.4\%$ ($\epsilon = 1$)。由于可以完全去除掩码信息，从实验评估结果来看 chain-PPFL 算法的训练精度整体上非常接近 FedAVG 且优于基于 DP 的 FL 算法，如图 3 所示。此外，$\epsilon$ 值越小，添加噪声的方差越大，精度下降越明显。

![图3 实验结果ab](images/../image/chain-PPFL/图3ab.png)
![图3 实验结果cd](images/../image/chain-PPFL/图3cd.png)

另一方面，由于在模型训练过程中增加了噪声，基于 DP 的 FL 方案不可避免地大幅增加了迭代轮数，导致收敛速度较慢，如表 III 所示。相比之下，chain-PPFL 算法要达到大致相同的精度水平所消耗的训练轮数与 FedAVG 算法基本相同，而远远小于基于 DP 的 FL 算法所消耗的轮数。

表 III，训练轮次对比（平均值）

| 在数据分布上的<br />模型 & 精度 | FedAVG        | Chain-PPFL    | 应用 DP 的 FL<br />($\epsilon =8$) | 应用 DP 的 FL<br />($\epsilon =1$) |
| :-----------------------------: | ------------- | ------------- | ------------------------------------ | ------------------------------------|
|    Non-IID 的 CNN，$98\%$    | 1.2$\times$ | 1.2$\times$ | 1.5$\times$                        | 1.2$\times$                        |
|      IID 的 CNN，$99\%$      | 1.0$\times$ | 1.0$\times$ | 1.8$\times$                        | 3.0$\times$                        |
|    Non-IID 的 CNN，$92\%$    | 1.2$\times$ | 1.2$\times$ | 2.0$\times$                        | 2.0$\times$                        |
|      IID 的 CNN，$95\%$      | 1.0$\times$ | 1.0$\times$ | 1.2$\times$                        | 1.2$\times$                        |
|(数量级：$10^2$  轮)|||||

在泄漏防御的对比测试中，我们使用 L-BFGS 匹配 FL 中训练模型所有参数的梯度^[match gradients from all parameters of the training model]，实验使用随机的初始权重。梯度匹配损失^[gradient matching loss]反映了原始样本的差异程度。梯度匹配损失值越小，泄露的信息越多。当匹配损失函数值大于 0.15 时没有信息泄露。图 4 给出了泄漏防御效果的实验结果。从图 4 中可以看出，FedAVG 和基于 DP 的 FL 方案都无法防止敏感信息的泄漏，而我们的方法则成功地实现了隐私保护。

![图4 泄漏防御效果](images/../image/chain-PPFL/图4泄漏防御效果.png)

总之，上述所有实验结果表明，chain-PPFL 相比于基于 DP 的 FL 能够获得更好的精度。由于 chain-PPFL 能够用掩码信息完美抵消增加的噪声，其性能甚至非常接近未考虑隐私保护的原始 FedAVG 算法。

## VI. 结论

本文提出了一种基于链式 SMC 技术的隐私保护 FL 框架：chain-PPFL。分析和实验结果表明，在精度损失和计算复杂度几乎与 FedAVG 算法相当的情况下，chainPPFL 方案也能达到较好的隐私保护水平。此外，chain-PPFL 的架构相对简洁，适用于一些通信环境较好的实际场景，如边缘云、智能物联网或智慧城市等。未来，我们的研究工作将重点关注 chain-PPFL 的优化和在去中心化 FL 环境中的应用。

## 参考文献

1. H. B. McMahan, E. Moore, D. Ramage, S. Hampson and B. A. Y. Arcas, Communication-efficient learning of deep networks from decentralized data, 2016,  [online]  Available: [http://arXiv:1602.05629](http://arXiv:1602.05629).

2. J. Konečnỳ, H. B. McMahan, D. Ramage and P. Richtárik, Federated optimization: Distributed machine learning for on-device intelligence, 2016,  [online]  Available: [http://arXiv:1610.02527](http://arXiv:1610.02527).

3. J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh and D. Bacon, Federated learning: Strategies for improving communication efficiency, 2016,  [online]  Available: [http://arXiv:1610.05492](http://arXiv:1610.05492).

4. L. Melis, C. Song, E. De Cristofaro and V. Shmatikov, "Exploiting unintended feature leakage in collaborative learning", Proc. IEEE Symp. Security Privacy (SP), pp. 691-706, 2019.

5. L. Zhu, Z. Liu and S. Han, "Deep leakage from gradients" in Advances in Neural Information Processing Systems 32, Vancouver, BC, Canada:Curran Assoc., Inc, pp. 14774-14784, 2019.

6. B. Zhao, K. R. Mopuri and H. Bilen, iDLG: Improved deep leakage from gradients, 2020,  [online]  Available: [http://arXiv:2001.02610](http://arXiv:2001.02610).

7. M. Abadi et al., "Deep learning with differential privacy", Proc. ACM SIGSAC Conf. Comput. Commun. Security, pp. 308-318, 2016.

8. R. C. Geyer, T. Klein and M. Nabi, Differentially private federated learning: A client level perspective, 2017,  [online]  Available: [http://arXiv:1712.07557](http://arXiv:1712.07557).

9. N. Wu, F. Farokhi, D. Smith and M. A. Kaafar, "The value of collaboration in convex machine learning with differential privacy", Proc. IEEE Symp. Security Privacy (SP), pp. 466-479, 2020.

10. T. Wang, Y. Mei, W. Jia, X. Zheng, G. Wang and M. Xie, "Edge-based differential privacy computing for sensor–cloud systems", J. Parallel Distrib. Comput., vol. 136, pp. 75-85, Feb. 2020.

11. S. Hardy et al., Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption, 2017,  [online]  Available: [http://arXiv:1711.10677](http://arXiv:1711.10677).

12. R. Nock et al., Entity resolution and federated learning get a federated resolution, 2018,  [online]  Available: [http://arXiv:1803.04035](http://arXiv:1803.04035).

13. P. Kairouz et al., Advances and open problems in federated learning, 2019,  [online]  Available: [http://arXiv:1912.04977](http://arXiv:1912.04977).

14. K. Bonawitz et al., "Practical secure aggregation for privacy-preserving machine learning", Proc. ACM SIGSAC Conf. Comput. Commun. Security, pp. 1175-1191, 2017.

15. K. Mandal, G. Gong and C. Liu, "Nike-based fast privacy-preserving high-dimensional data aggregation for mobile devices", 2018.

16. G. Xu, H. Li, S. Liu, K. Yang and X. Lin, "VerifyNet: Secure and verifiable federated learning", IEEE Trans. Inf. Forensics Security, vol. 15, pp. 911-926, 2019.

17. Q. Li and M. G. Christensen, "A privacy-preserving asynchronous averaging algorithm based on shamir’s secret sharing", Proc. IEEE 27th Eur. Signal Process. Conf. (EUSIPCO), pp. 1-5, 2019.

18. L. T. Phong, Y. Aono, T. Hayashi, L. Wang and S. Moriai, "Privacy-preserving deep learning via additively homomorphic encryption", IEEE Trans. Inf. Forensics Security, vol. 13, pp. 1333-1345, 2017.

19. J. Yuan and S. Yu, "Privacy preserving back-propagation neural network learning made practical with cloud computing", IEEE Trans. Parallel Distrib. Syst., vol. 25, no. 1, pp. 212-221, Jan. 2014.

20. K. Umapavankumar, S. Srinivasu, S. S. N. Rao and S. T. Rao, "Machine learning usage in Facebook Twitter and Google along with the other tools" in Emerging Research in Data Engineering Systems and Computer Communications, Singapore:Springer, pp. 465-471, 2020.

21. S. Deep, X. Zheng, A. Jolfaei, D. Yu, P. Ostovari and A. Kashif Bashir, "A survey of security and privacy issues in the Internet of Things from the layered context", Trans. Emerg. Telecommun. Technol., Mar. 2020.

22. A. K. Sangaiah, J. S. A. Dhanaraj, P. Mohandas and A. Castiglione, "Cognitive IoT system with intelligence techniques in sustainable computing environment", Comput. Commun., vol. 154, pp. 347-360, Mar. 2020.

23. X. Xu, K. Lin, H. Lu, L. Gao and H. T. Shen, "Correlated features synthesis and alignment for zero-shot cross-modal retrieval", Proc. 43rd Int. ACM SIGIR Conf. Res. Develop. Inf. Retrieval, pp. 1419-1428, 2020.

24. H. Lu, M. Wang and A. K. Sangaiah, "Human emotion recognition using an EEG cloud computing platform", Mobile Netw. Appl., vol. 25, no. 3, pp. 1023-1032, 2020.

25. T. Li, A. K. Sahu, A. Talwalkar and V. Smith, "Federated learning: Challenges methods and future directions", IEEE Signal Process. Mag., vol. 37, no. 3, pp. 50-60, May 2020.

26. Z. Brakerski, "Fully homomorphic encryption without modulus switching from classical GapSVP", Proc. Annu. Cryptol. Conf., pp. 868-886, 2012.

27. J. Fan and F. Vercauteren, "Somewhat practical fully homomorphic encryption", 2012.

28. Z. Brakerski, C. Gentry and V. Vaikuntanathan, "(leveled) fully homomorphic encryption without bootstrapping", ACM Trans. Comput. Theory, vol. 6, no. 3, pp. 1-36, 2014.

29. J.-S. Coron, T. Lepoint and M. Tibouchi, "Scale-invariant fully homomorphic encryption over the integers", Proc. 17th Int. Workshop Public Key Cryptogr., pp. 311-328, 2014.

30. C. Gentry, "Fully homomorphic encryption using ideal lattices", Proc. 41st Annu. ACM Symp. Theory Comput., pp. 169-178, 2009.

31. Z. Min, G. Yang, A. K. Sangaiah, S. Bai and G. Liu, "A privacy protection-oriented parallel fully homomorphic encryption algorithm in cyber physical systems", EURASIP J. Wireless Commun. Netw., vol. 6958, no. 1, pp. 15, 2019.

32. P. Vepakomma, T. Swedish, R. Raskar, O. Gupta and A. Dubey, No peek: A survey of private distributed deep learning, 2018,  [online]  Available: [http://arXiv:1812.03288](http://arXiv:1812.03288).

33. A. Shamir, "How to share a secret", Commun. ACM, vol. 22, no. 11, pp. 612-613, 1979.

34. G. Ács and C. Castelluccia, "I have a DREAM! (DiffeRentially privatE smArt metering)", Proc. Int. Workshop Inf. Hiding, pp. 118-132, 2011.

35. T. Elahi, G. Danezis and I. Goldberg, "PrivEx: Private collection of traffic statistics for anonymous communication networks", Proc. ACM SIGSAC Conf. Comput. Commun. Security, pp. 1068-1079, 2014.

36. S. Goryczka and L. Xiong, "A comprehensive comparison of multiparty secure additions with differential privacy", IEEE Trans. Depend. Secure Comput., vol. 14, no. 5, pp. 463-477, Sep./Oct. 2017.

37. T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar and V. Smithy, "FedDANE: A federated newton-type method", Proc. IEEE 53rd Asilomar Conf. Signals Syst. Comput., pp. 1227-1231, 2019.

38. "Efficient neighbor list creation for cellular networks", Dec. 2011.

39. H. Zhao, C. Wang, Y. Zhu and W. Lin, "P2P network based on neighbor-neighbor lists", J. Phys. Conf. Series, vol. 1168, no. 3, 2019.

40. L. Liu, J. Zhang, S. Song and K. B. Letaief, Client-edge-cloud hierarchical federated learning, 2019,  [online]  Available: [http://arXiv:1905.06641](http://arXiv:1905.06641).

41. S. Ji, S. Pan, G. Long, X. Li, J. Jiang and Z. Huang, "Learning private neural language modeling with attentive aggregation", Proc. IEEE Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-8, 2019.

42. P. Adam et al., "Automatic differentiation in pytorch", Proc. Neural Inf. Process. Syst., pp. 8026-8037, 2017.

## 后记

> 文献翻译：谷文聪

> 原文链接：[Privacy-Preserving Federated Learning Framework Based on Chained Secure Multiparty Computing](https://ieeexplore.ieee.org/document/9187932)
>> 不确定的翻译标记在注脚中。

<!-- [Privacy-Preserving Federated Learning Framework Based on Chained Secure Multiparty Computing]:/Users/yucharlotte/Downloads/safari下载/PPFLBased%Chained%Secure%Multiparty%Computing.pdf -->
